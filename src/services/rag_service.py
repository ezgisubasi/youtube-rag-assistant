# src/services/rag_service.py
"""
Professional RAG Service with LLM-based confidence evaluation.
Production-ready implementation for portfolio demonstration.
"""

from typing import List, Optional
from dataclasses import dataclass
import sys
from pathlib import Path
import os
import re
import traceback

import google.generativeai as genai
from langchain_google_genai import ChatGoogleGenerativeAI

print("üîç [DEBUG] Starting rag_service.py import")

# Add src to path for imports
current_dir = Path(__file__).parent
src_dir = current_dir.parent
sys.path.append(str(src_dir))

from core.models import SearchResult, RAGResponse
from core.config import get_config, get_prompts
from services.vector_service import VectorService
from services.web_search_service import WebSearchService

@dataclass
class RAGConfig:
    """RAG service configuration."""
    model_name: str
    api_key: str
    temperature: float = 0.7
    max_tokens: int = 1024
    min_similarity_threshold: float = 0.1  # Lowered for testing
    search_top_k: int = 5
    # LLM confidence thresholds
    high_confidence_threshold: float = 0.75
    medium_confidence_threshold: float = 0.3  # Lowered for testing

class RAGService:
    """
    Professional RAG service with LLM-based confidence evaluation.
    
    Features:
    - Vector-based semantic search
    - LLM confidence scoring
    - Intelligent web search fallback
    - Language matching validation
    - Professional error handling
    """
    
    def __init__(self):
        """Initialize RAG service with all components."""
        print("üîç [DEBUG] RAGService.__init__ started")
        print("Initializing RAG Service with LLM Confidence...")
        
        # Load configuration
        print("üîç [DEBUG] Loading configuration...")
        config = get_config()
        gemini_api_key = config.gemini_api_key or os.getenv("GEMINI_API_KEY")
        
        if not gemini_api_key:
            raise ValueError("GEMINI_API_KEY not found")
        
        # Create RAG configuration
        self.config = RAGConfig(
            model_name=config.model_name or "gemini-1.5-flash",
            api_key=gemini_api_key
        )
        
        print(f"üîç [DEBUG] RAG Config thresholds:")
        print(f"  - min_similarity_threshold: {self.config.min_similarity_threshold}")
        print(f"  - medium_confidence_threshold: {self.config.medium_confidence_threshold}")
        print(f"  - high_confidence_threshold: {self.config.high_confidence_threshold}")
        
        # Initialize Gemini AI
        print("üîç [DEBUG] Initializing Gemini AI...")
        genai.configure(api_key=self.config.api_key)
        self.llm = ChatGoogleGenerativeAI(
            model=self.config.model_name,
            google_api_key=self.config.api_key,
            temperature=self.config.temperature,
            max_output_tokens=self.config.max_tokens
        )
        print("‚úÖ [DEBUG] Gemini AI initialized")
        
        # Initialize services
        print("üîç [DEBUG] Initializing vector service...")
        self.vector_service = VectorService()
        self.vector_service.initialize_vector_store()
        print("‚úÖ [DEBUG] Vector service initialized")
        
        print("üîç [DEBUG] Initializing web search service...")
        self.web_search_service = WebSearchService()
        print("‚úÖ [DEBUG] Web search service initialized")
        
        # Prompt templates for response generation
        self.prompts = {
            'turkish': {
                'youtube': """Sen, yalnƒ±zca a≈üaƒüƒ±daki i√ßerikten yola √ßƒ±karak, kullanƒ±cƒ±nƒ±n sorusunu T√ºrk√ße ve profesyonel bir dille yanƒ±tlayan bir yapay zek√¢ asistansƒ±n.

ƒ∞√ßerik:
{video_content}

Soru:
{question}

Kurallar:
- Yanƒ±tƒ± tamamen T√ºrk√ße yaz
- 'Ben', 'bana', 'bizi', 'bence' gibi ifadeleri kullanma
- 'Videoda', 'video i√ßeriƒüine g√∂re' gibi ifadeler kullanma
- Bilgiyi tarafsƒ±z, profesyonel ve akademik bir dilde aktar
- Cevap 4‚Äì6 c√ºmle uzunluƒüunda olsun
- Gereksiz s√ºsleme yapma, net ol

Yanƒ±t:""",
                'web': """Sen, yalnƒ±zca a≈üaƒüƒ±daki web aramasƒ± sonucundan yola √ßƒ±karak, kullanƒ±cƒ±nƒ±n sorusunu T√ºrk√ße ve profesyonel bir dille yanƒ±tlayan bir yapay zek√¢ asistansƒ±n.

Web Aramasƒ± Sonucu:
{web_content}

Soru:
{question}

Kurallar:
- Yanƒ±tƒ± tamamen T√ºrk√ße yaz
- 'Ben', 'bana', 'bizi', 'bence' gibi ifadeleri kullanma
- 'Web'de', 'ara≈ütƒ±rmaya g√∂re' gibi ifadeler kullanma
- Bilgiyi tarafsƒ±z, profesyonel ve akademik bir dilde aktar
- Cevap 4‚Äì6 c√ºmle uzunluƒüunda olsun
- G√ºncel bilgileri vurgula

Yanƒ±t:"""
            },
            'english': {
                'youtube': """You are an AI assistant that answers user questions professionally in English, based solely on the provided content.

Content:
{video_content}

Question:
{question}

Rules:
- Answer entirely in English
- Don't use phrases like 'I', 'me', 'us', 'in my opinion'
- Don't use phrases like 'in the video', 'according to the video'
- Present information neutrally and professionally
- Keep answer 4-6 sentences long
- Be direct and clear

Answer:""",
                'web': """You are an AI assistant that answers user questions professionally in English, based solely on the provided web search results.

Web Search Results:
{web_content}

Question:
{question}

Rules:
- Answer entirely in English
- Don't use phrases like 'I', 'me', 'us', 'in my opinion'
- Don't use phrases like 'according to web search', 'the search shows'
- Present information neutrally and professionally
- Keep answer 4-6 sentences long
- Emphasize current information

Answer:"""
            }
        }
        
        print("‚úÖ [DEBUG] RAG Service initialized successfully")
    
    def detect_language(self, text: str) -> str:
        """Detect if text is Turkish or English."""
        print(f"üîç [DEBUG] Detecting language for: '{text[:50]}...'")
        
        # Turkish-specific characters
        turkish_chars = set('√ßƒüƒ±√∂≈ü√º√áƒûIƒ∞√ñ≈û√ú')
        
        # Turkish language indicators
        turkish_words = {
            'nedir', 'nasƒ±l', 'neden', 'hangi', 'kimse', 'hi√ß', 'i√ßin', 'olan',
            'bu', 'bir', 'de', 'da', 'ile', 've', 'veya', 'ama', 'fakat',
            '√ß√ºnk√º', 'belki', 'her', 'bazƒ±', 't√ºm', 'b√ºt√ºn', '≈üey', 'zaman',
            'yer', 'g√ºn', 'yƒ±l', 'ki≈üi', 'insan', 'iyi', 'k√∂t√º', 'b√ºy√ºk',
            'k√º√ß√ºk', 'yeni', 'eski', 'var', 'yok', 'et', 'ol', 'yap', 'gel',
            'git', 'al', 'ver', 'g√∂r', 'bil', 'iste', 's√∂yle', '√ßalƒ±≈ü',
            'ya≈üa', '√∂ƒüren', 'anla', 'd√º≈ü√ºn', 'inan', 'hakkƒ±nda', '√ºzerine',
            'kar≈üƒ±', 'doƒüru', 'g√∂re', 'kadar', '√∂nce', 'sonra', '≈üimdi',
            'daha', '√ßok', 'az', 'en', 'mi', 'mƒ±', 'mu', 'm√º', 'misin',
            'musun', 'neler', 'ne', 'kim', 'nerede', 'ne zaman', 'ni√ßin',
            'merhaba', 'g√ºnaydƒ±n', 'iyi g√ºnler', 'te≈üekk√ºr', 'l√ºtfen'
        }
        
        text_lower = text.lower()
        words = re.findall(r'\b\w+\b', text_lower)
        
        # Check for Turkish characters
        if any(char in text for char in turkish_chars):
            print("‚úÖ [DEBUG] Turkish characters detected")
            return 'turkish'
        
        # Count Turkish words and suffixes
        turkish_score = 0
        for word in words:
            if word in turkish_words:
                turkish_score += 2
            elif any(word.endswith(suffix) for suffix in ['ler', 'lar', 'dir', 'dƒ±r', 'mi≈ü', 'mu≈ü', 'lik', 'lƒ±k']):
                turkish_score += 1
        
        # Check for Turkish question patterns
        if re.search(r'\b(nasƒ±l|neden|ne|nedir|hangi|kim|nerede|ne zaman)\b', text_lower):
            turkish_score += 3
        
        result = 'turkish' if turkish_score > 0 else 'english'
        print(f"‚úÖ [DEBUG] Language detected: {result} (score: {turkish_score})")
        return result
    
    def evaluate_response_quality(self, query: str, response: str, language: str) -> float:
        """Evaluate response quality using LLM."""
        print(f"üîç [DEBUG] evaluate_response_quality called")
        print(f"üîç [DEBUG] Query: '{query[:50]}...'")
        print(f"üîç [DEBUG] Response: '{response[:100]}...'")
        print(f"üîç [DEBUG] Language: {language}")
        
        try:
            if language == 'turkish':
                eval_prompt = f"""Bu RAG yanƒ±tƒ±nƒ±n kalitesini deƒüerlendir:

Sorgu: {query}
Yanƒ±t: {response}

Bu yanƒ±t kullanƒ±cƒ±nƒ±n sorusunu ne kadar iyi yanƒ±tlƒ±yor? Alakalƒ±, doƒüru, tam ve anla≈üƒ±lƒ±r mƒ±?

0.0 (√ßok k√∂t√º) ile 1.0 (m√ºkemmel) arasƒ±nda bir puan ver.

Sadece sayƒ± ver:"""
            else:
                eval_prompt = f"""Evaluate the quality of this RAG response:

Query: {query}
Response: {response}

How well does this response answer the user's question? Consider relevance, accuracy, completeness, and clarity.

Rate from 0.0 (very poor) to 1.0 (excellent).

Return only the number:"""
            
            print("üîç [DEBUG] Calling LLM for confidence evaluation...")
            eval_response = self.llm.invoke(eval_prompt)
            confidence_text = eval_response.content.strip()
            print(f"üîç [DEBUG] LLM response: '{confidence_text}'")
            
            # Extract confidence score
            numbers = re.findall(r'0\.\d+|1\.0|0\.0', confidence_text)
            print(f"üîç [DEBUG] Extracted numbers: {numbers}")
            
            if numbers:
                confidence = float(numbers[0])
                result = max(0.0, min(1.0, confidence))
                print(f"‚úÖ [DEBUG] Final LLM confidence: {result}")
                return result
            
            print("‚ö†Ô∏è [DEBUG] No valid confidence score found, using fallback 0.5")
            return 0.5  # Fallback
            
        except Exception as e:
            print(f"‚ùå [DEBUG] Error evaluating response quality: {e}")
            print(f"‚ùå [DEBUG] Traceback: {traceback.format_exc()}")
            return 0.5
    
    def generate_response(self, query: str) -> RAGResponse:
        """
        Generate response using RAG with LLM confidence evaluation.
        
        Flow:
        1. Vector search for relevant content
        2. Language compatibility check
        3. Generate RAG response
        4. Evaluate response quality with LLM
        5. Return high-quality response or fallback to web search
        """
        print(f"üîç [DEBUG] generate_response called with: '{query}'")
        
        try:
            # Detect query language
            query_language = self.detect_language(query)
            print(f"‚úÖ [DEBUG] Query language: {query_language}")
            
            # Get best YouTube content
            print("üîç [DEBUG] Getting YouTube content...")
            youtube_result = self._get_youtube_content(query)
            
            if not youtube_result:
                print("‚ö†Ô∏è [DEBUG] No YouTube content found, going to web search")
                return self._web_search_fallback(query, query_language)
            
            print(f"‚úÖ [DEBUG] YouTube content found: {youtube_result.video_title[:50]}...")
            print(f"üîç [DEBUG] Vector similarity score: {youtube_result.similarity_score}")
            
            # Check language compatibility
            print("üîç [DEBUG] Checking language compatibility...")
            content_language = self.detect_language(youtube_result.text_content[:500])
            print(f"‚úÖ [DEBUG] Content language: {content_language}")
            
            if query_language != content_language:
                print(f"‚ö†Ô∏è [DEBUG] Language mismatch: query={query_language}, content={content_language}")
                return self._web_search_fallback(query, query_language)
            
            # Check similarity threshold
            print(f"üîç [DEBUG] Similarity check: {youtube_result.similarity_score} >= {self.config.min_similarity_threshold}")
            if youtube_result.similarity_score < self.config.min_similarity_threshold:
                print("‚ö†Ô∏è [DEBUG] Similarity below threshold, going to web search")
                return self._web_search_fallback(query, query_language)
            
            # Generate RAG response
            print("üîç [DEBUG] Generating RAG answer...")
            rag_answer = self._generate_youtube_answer(query, youtube_result, query_language)
            print(f"‚úÖ [DEBUG] RAG answer: '{rag_answer[:100]}...'")
            
            # THE CRITICAL PART: Evaluate response quality using LLM
            print("üîç [DEBUG] *** EVALUATING LLM CONFIDENCE ***")
            llm_confidence = self.evaluate_response_quality(query, rag_answer, query_language)
            print(f"üîç [DEBUG] *** LLM CONFIDENCE RESULT: {llm_confidence} ***")
            
            # Decision based on LLM confidence
            print(f"üîç [DEBUG] *** CONFIDENCE DECISION ***")
            print(f"üîç [DEBUG] LLM confidence: {llm_confidence}")
            print(f"üîç [DEBUG] Medium threshold: {self.config.medium_confidence_threshold}")
            print(f"üîç [DEBUG] Passes threshold: {llm_confidence >= self.config.medium_confidence_threshold}")
            
            if llm_confidence >= self.config.medium_confidence_threshold:
                # High or medium confidence - use RAG response
                print("‚úÖ [DEBUG] *** USING RAG RESPONSE (HIGH CONFIDENCE) ***")
                return RAGResponse(
                    query=query,
                    answer=rag_answer,
                    sources=[youtube_result],
                    confidence_score=llm_confidence  # THIS should be the LLM confidence, not similarity
                )
            else:
                # Low confidence - fallback to web search
                print("‚ö†Ô∏è [DEBUG] *** FALLING BACK TO WEB SEARCH (LOW CONFIDENCE) ***")
                return self._web_search_fallback(query, query_language)
            
        except Exception as e:
            print(f"‚ùå [DEBUG] Error generating response: {e}")
            print(f"‚ùå [DEBUG] Traceback: {traceback.format_exc()}")
            language = self.detect_language(query)
            error_message = (
                f"Yanƒ±t olu≈üturulurken hata olu≈ütu: {str(e)}" 
                if language == 'turkish' 
                else f"Error generating response: {str(e)}"
            )
            return RAGResponse(
                query=query,
                answer=error_message,
                sources=[],
                confidence_score=0.0
            )
    
    def _get_youtube_content(self, query: str) -> Optional[SearchResult]:
        """Get best YouTube content from vector search."""
        print(f"üîç [DEBUG] _get_youtube_content called with: '{query}'")
        try:
            search_results = self.vector_service.search(query, top_k=self.config.search_top_k)
            result = search_results[0] if search_results else None
            if result:
                print(f"‚úÖ [DEBUG] Found YouTube content: {result.video_title[:50]}...")
            else:
                print("‚ö†Ô∏è [DEBUG] No YouTube content found")
            return result
        except Exception as e:
            print(f"‚ùå [DEBUG] YouTube search error: {e}")
            return None
    
    def _generate_youtube_answer(self, question: str, video: SearchResult, language: str) -> str:
        """Generate answer from YouTube content."""
        print(f"üîç [DEBUG] _generate_youtube_answer called for language: {language}")
        try:
            prompt = self.prompts[language]['youtube'].format(
                video_content=video.text_content,
                question=question
            )
            print("üîç [DEBUG] Invoking LLM for YouTube answer...")
            response = self.llm.invoke(prompt)
            answer = response.content.strip()
            print(f"‚úÖ [DEBUG] YouTube answer generated: {answer[:100]}...")
            return answer
        except Exception as e:
            print(f"‚ùå [DEBUG] Error generating YouTube answer: {e}")
            return (
                "YouTube i√ßeriƒüi i≈ülenirken hata olu≈ütu." 
                if language == 'turkish' 
                else "Error processing YouTube content."
            )
    
    def _generate_web_answer(self, question: str, web_content: str, language: str) -> str:
        """Generate answer from web content."""
        print(f"üîç [DEBUG] _generate_web_answer called for language: {language}")
        try:
            prompt = self.prompts[language]['web'].format(
                web_content=web_content,
                question=question
            )
            print("üîç [DEBUG] Invoking LLM for web answer...")
            response = self.llm.invoke(prompt)
            answer = response.content.strip()
            print(f"‚úÖ [DEBUG] Web answer generated: {answer[:100]}...")
            return answer
        except Exception as e:
            print(f"‚ùå [DEBUG] Error generating web answer: {e}")
            return (
                "Web i√ßeriƒüi i≈ülenirken hata olu≈ütu." 
                if language == 'turkish' 
                else "Error processing web content."
            )
    
    def _web_search_fallback(self, query: str, language: str) -> RAGResponse:
        """Fallback to web search when RAG confidence is low."""
        print(f"üîç [DEBUG] _web_search_fallback called for language: {language}")
        try:
            web_result = self.web_search_service.search(query)
            
            if web_result:
                print(f"‚úÖ [DEBUG] Web search result found: {web_result.title[:50]}...")
                web_answer = self._generate_web_answer(query, web_result.snippet, language)
                
                # Evaluate web response quality too
                web_confidence = self.evaluate_response_quality(query, web_answer, language)
                
                web_search_result = SearchResult(
                    video_id="web_search",
                    video_title=web_result.title,
                    video_url=web_result.url,
                    text_content=web_result.snippet,
                    similarity_score=web_confidence  # This will be the LLM confidence for web results
                )
                
                return RAGResponse(
                    query=query,
                    answer=web_answer,
                    sources=[web_search_result],
                    confidence_score=web_confidence  # LLM confidence, not similarity
                )
            
            # No content found anywhere
            print("‚ö†Ô∏è [DEBUG] No web content found either")
            no_content_message = (
                "Bu soruya yanƒ±t verebilmek i√ßin hem video ar≈üivimde hem de web'de yeterli bilgi bulunamadƒ±." 
                if language == 'turkish' 
                else "Insufficient information found in both video archive and web search."
            )
            
            return RAGResponse(
                query=query,
                answer=no_content_message,
                sources=[],
                confidence_score=0.0
            )
            
        except Exception as e:
            print(f"‚ùå [DEBUG] Web search fallback error: {e}")
            return RAGResponse(
                query=query,
                answer=f"Web search failed: {str(e)}",
                sources=[],
                confidence_score=0.0
            )

print("‚úÖ [DEBUG] rag_service.py import completed")